{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu_0AWzfKmiP"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OSIksBfZGVM",
        "outputId": "5acccaaa-63f3-4f7b-8e1f-df107fcb503f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.218)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.8)\n",
            "Requirement already satisfied: langchainplus-sdk>=0.0.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.17)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.7.9)\n",
            "Requirement already satisfied: argilla in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.11.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.2)\n",
            "Requirement already satisfied: msg-parser in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.5.3)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.3)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured) (20221105)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.4.0)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.11)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.11)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.21)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.10)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Requirement already satisfied: httpx<0.24,>=0.15 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.23.3)\n",
            "Requirement already satisfied: deprecated~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.2.14)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (23.1)\n",
            "Requirement already satisfied: pydantic>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.10.9)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (4.65.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (2.2.1)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.6)\n",
            "Requirement already satisfied: rich<=13.0.1 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (13.0.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from msg-parser->unstructured) (0.46)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (2.0.12)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (41.0.1)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx->unstructured) (3.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.5.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.7->argilla->unstructured) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.7.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (1.1.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.3.26)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.9)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.6.4)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.8.1)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.98.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.6.3)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.2.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.15.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.16)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.7.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.1.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (0.29.35)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
            "Requirement already satisfied: azure-storage-blob in /usr/local/lib/python3.10/dist-packages (12.16.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (1.27.1)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (41.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.6.3)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (0.6.1)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2.31.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2023.5.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken\n",
        "!pip install azure-storage-blob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udSm0vm0KgQo"
      },
      "source": [
        "# Imports and API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Sqcr1yasXn"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader, DirectoryLoader, UnstructuredPowerPointLoader, Docx2txtLoader\n",
        "from langchain.document_loaders import AzureBlobStorageContainerLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BosiBdhLbBKL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCMR4CMRKWa7"
      },
      "source": [
        "# Google Drive Mount and Import #don't execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Zpe8aKbJ8w",
        "outputId": "6c67f6c7-41eb-4269-c42f-c2109f98d972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hI_c9NQOdLhl",
        "outputId": "c6e299ca-99a2-4733-b6df-5a584b117ff6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Northwind_Standard_Benefits_Details.pdf',\n",
              " 'CauseAndEffectOfHomelessness.txt',\n",
              " 'CauseAndEffectOfHomelessness2.txt',\n",
              " 'CauseAndEffectOfHomelessness3.txt',\n",
              " 'Northwind_Health_Plus_Benefits_Details (1).pdf',\n",
              " 'Benefit_Options.pdf',\n",
              " 'PerksPlus.pdf',\n",
              " 'role_library.pdf',\n",
              " 'File Viewer Migration factory.pdf']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#don't execute\n",
        "\n",
        "root_dir = \"/content/drive/My Drive\"\n",
        "pdf_folder_path = f'{root_dir}/Knowledge Base/'\n",
        "#os.listdir(pdf_folder_path)\n",
        "os.listdir('/content/drive/MyDrive/Knowledge Base')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjfy0993JxHF"
      },
      "source": [
        "# File and Directory Loaders #don't execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnsEV70wdvuH"
      },
      "outputs": [],
      "source": [
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NReIWnXROSlN"
      },
      "outputs": [],
      "source": [
        "text_loader = DirectoryLoader('/content/drive/MyDrive/Knowledge Base', glob='**/*.txt')\n",
        "pdf_loader = DirectoryLoader('/content/drive/MyDrive/Knowledge Base', glob='**/*.pdf')\n",
        "readme_loader = DirectoryLoader('/content/drive/MyDrive/Knowledge Base', glob='**/*.md')\n",
        "doc_loader = DirectoryLoader('/content/drive/MyDrive/Knowledge Base', glob='**/*.docx')\n",
        "ppt_loader = DirectoryLoader('/content/drive/MyDrive/Knowledge Base', glob='**/*.pptx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYKW7kHIeON7"
      },
      "outputs": [],
      "source": [
        "loaders = [pdf_loader, readme_loader, text_loader, doc_loader, ppt_loader]\n",
        "documents = []\n",
        "for loader in loaders:\n",
        "  documents.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKtAZXWRGqHj",
        "outputId": "1d597f6e-6e1a-4d7f-81b2-f5e517b5dfea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 11 documents in your data\n"
          ]
        }
      ],
      "source": [
        "print(f'You have {len(documents)} documents in your data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yQNPRiKea61"
      },
      "source": [
        "# Vector Store Index Creator for Directory Loader don't execute\n",
        "1. Splitting documents into chunks\n",
        "2. Creating embeddings for each document\n",
        "3. Storing documents and embeddings in a vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vIlUICO1fEiJ",
        "outputId": "e0b0cc75-6057-4a90-d0d8-6b8097ce55d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1386, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 5951, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2670, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1144, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1261, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1865, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1062, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1257, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1053, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1258, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2507, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1095, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1098, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1077, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1052, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1658, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1159, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1114, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1216, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1490, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1053, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1338, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1119, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1644, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1119, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1946, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1676, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1424, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1163, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1124, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1279, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1019, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1269, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1091, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1274, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1009, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1008, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1235, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1006, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1192, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1447, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1494, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1120, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1158, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1357, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1023, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1025, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1134, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1083, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1331, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1084, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1038, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2312, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1130, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1374, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1007, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1016, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1674, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1067, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2950, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1029, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1232, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1073, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1277, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1119, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1662, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1079, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1021, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1325, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3063, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2153, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3944, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1175, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2360, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1058, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1417, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1033, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1158, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1135, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1718, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1166, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1048, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1093, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1127, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1005, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1273, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1106, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1311, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1206, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1479, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1127, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1470, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1034, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1049, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1038, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1029, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1071, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1103, which is longer than the specified 1000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2641, which is longer than the specified 1000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VectorStoreIndexWrapper(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7f0c3ac27490>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = VectorstoreIndexCreator(vectorstore_cls=Chroma,embedding=OpenAIEmbeddings(),text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)).from_loaders([loaders])\n",
        "index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRGJ1AChLA-5"
      },
      "source": [
        "# Blob Loader with VectorstoreIndex Creator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWAqabm7SZU4"
      },
      "outputs": [],
      "source": [
        "loaders = AzureBlobStorageContainerLoader(conn_str=\"DefaultEndpointsProtocol=https;AccountName=ishitagptblob1;\",container=\"ishita-container-langchain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMt2mZNkRlHB"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ocwRFCzUCk_",
        "outputId": "510a7304-d8d4-4283-a42c-17d22cbeae98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 17 documents in your data\n"
          ]
        }
      ],
      "source": [
        "documents = loaders.load()\n",
        "print(f'You have {len(documents)} documents in your data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcP4hwUGXXG-"
      },
      "outputs": [],
      "source": [
        "index = VectorstoreIndexCreator().from_loaders([loaders])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y-T_-eyMR7E"
      },
      "source": [
        "# Text Splitter, Embeddings, VectorStore and Index\n",
        "**Not Needed as we have VectorstoreIndexCreator which is a wrapper around this logic**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoLSAdN3Ubzx"
      },
      "outputs": [],
      "source": [
        "#text splitter - split the documents into chunks.\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(documents)\n",
        "print(len(documents))\n",
        "\n",
        "#select which embeddings we want to use\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "#create the vectorstore to use as the index.\n",
        "db = Chroma.from_documents(documents, embeddings)\n",
        "\n",
        "#expose this index in a retriever interface.\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "#create a chain and use it to answer questions\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "query = \"What is the Northwind Standard Health Plan\"\n",
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzCvnKQKKK3D"
      },
      "source": [
        "# Query and Source Query with multiple file formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfqzo_yLfiFR",
        "outputId": "26b4adf1-d1c6-404e-87a1-c7e2e5cef7a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The Northwind Standard Health Plan is a comprehensive health plan that provides coverage for medical, vision, and dental services, as well as preventive care services and prescription drug coverage. It offers a variety of in-network providers, including primary care physicians, specialists, hospitals, and pharmacies. It does not offer coverage for emergency services, mental health and substance abuse coverage, or out-of-network services.\n",
            "/tmp/tmptnb6rux_/ishita-container-langchain/Northwind_Standard_Benefits_Details.pdf, /tmp/tmpb5mb1qi7/ishita-container-langchain/Benefit_Options.pdf\n",
            "Benefit_Options.pdf\n"
          ]
        }
      ],
      "source": [
        "#with pdf\n",
        "print(index.query('What is the Northwind Standard Health Plan'))\n",
        "print(index.query_with_sources('What is the Northwind Standard Health Plan')['sources'])\n",
        "print((index.query_with_sources('What is the Northwind Standard Health Plan')['sources']).rsplit('/', 1)[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IGsb5idNHbD",
        "outputId": "3c9cdf07-6d23-44d0-bb7c-e8985a33895f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " To setup the CMAV tool, first download and unzip the file. Then open the “CloudMigrationAssessmentAndValidation.sln” file in Visual Studio or any other IDE. After that, open the “Configuration.json” file and set the values for different keys, according to the instructions provided. Finally, make sure that Python is installed in your IDE or system.\n",
            "/tmp/tmpduz3xsyq/ishita-container-langchain/test5.pdf, /tmp/tmpqluldfpn/ishita-container-langchain/Wiki.md\n",
            "Wiki.md\n"
          ]
        }
      ],
      "source": [
        "#with md\n",
        "print(index.query('How to setup CMAV tool'))\n",
        "print(index.query_with_sources('How to setup CMAV tool')['sources'])\n",
        "print((index.query_with_sources('How to setup CMAV tool')['sources']).rsplit('/', 1)[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKon97c1LXPU",
        "outputId": "4d423d22-2b16-42f0-87d3-abc2dec22e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The effects of homelessness can include poor health, personal and psychological decline, decreased access to opportunity, loss of job or income, poverty, substance abuse, violence in the home, and disability and illness.\n",
            "/tmp/tmp6ccv4j3o/ishita-container-langchain/CauseAndEffectOfHomelessness3.txt, /tmp/tmppcos27zq/ishita-container-langchain/CauseAndEffectOfHomelessness2.txt\n",
            "CauseAndEffectOfHomelessness2.txt\n"
          ]
        }
      ],
      "source": [
        "#with txt\n",
        "print(index.query('What are the effects of homelessness'))\n",
        "print(index.query_with_sources('What are the effects of homelessness')['sources'])\n",
        "print((index.query_with_sources('What are the effects of homelessnesss')['sources']).rsplit('/', 1)[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qCF17cGPjyM",
        "outputId": "a669d7ac-32ea-41d2-9395-ec3904c29d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I'm sorry, I don't know.\n",
            "/tmp/tmpzf4kdryi/ishita-container-langchain/test4.pdf\n",
            "test4.pdf\n"
          ]
        }
      ],
      "source": [
        "#with doc\n",
        "print(index.query('Tell me about criminal violence against Black Americans'))\n",
        "print(index.query_with_sources('Tell me about criminal violence against Black Americans')['sources'])\n",
        "print((index.query_with_sources('Tell me about criminal violence against Black Americans')['sources']).rsplit('/', 1)[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyPaI3sxTIM3",
        "outputId": "278e91c4-6b31-4073-ebe1-ec1cfa9ca475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The problem statement related to migration is that over a decade there are many artifacts built to support the growing need of Standard Operating Procedures, tools, User guides, Checklists/playbooks, automations, technical trackers and learnings. As an initial prototype, we are planning to build a ChatGPT kind of solution to help Factory team members to identify the artifacts and information that would enable them to consume the info more efficiently and will optimize their delivery.\n",
            "/tmp/tmpa27iixqq/ishita-container-langchain/test3.pdf, /tmp/tmposl3latb/ishita-container-langchain/OPEN AI-BASED FILE RETRIEVAL SYSTEM (1).pptx\n",
            "OPEN AI-BASED FILE RETRIEVAL SYSTEM (1).pptx\n"
          ]
        }
      ],
      "source": [
        "#with ppt\n",
        "print(index.query('Problem Statement Related to Migration'))\n",
        "print(index.query_with_sources('Problem Statement Related to Migration')['sources'])\n",
        "print((index.query_with_sources('Problem Statement Related to Migration')['sources']).rsplit('/', 1)[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRD6LaS4uu-s"
      },
      "source": [
        "#Downloadable file link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGKAgbH0u7in"
      },
      "outputs": [],
      "source": [
        "from azure.storage.blob import BlobServiceClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPbN0Nh1vtrP"
      },
      "outputs": [],
      "source": [
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=ishitagptblob1;EndpointSuffix=core.windows.net\"\n",
        "\n",
        "# Create a BlobServiceClient using the connection string\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU2FAS8rv7cj",
        "outputId": "98a7453f-98f3-4456-836a-f9b8179777c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter file name: test1.pdf\n"
          ]
        }
      ],
      "source": [
        "container_name = \"ishita-container-langchain\"\n",
        "file_name = input(\"Enter file name: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN5y3x9fPkpO",
        "outputId": "38a0a606-6757-4c55-e89f-e62644518731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benefit_Options.pdf\n",
            "CauseAndEffectOfHomelessness.txt\n",
            "CauseAndEffectOfHomelessness2.txt\n",
            "CauseAndEffectOfHomelessness3.txt\n",
            "Crime with Violence in USA and SA.docx\n",
            "EmpSampledata.csv\n",
            "Northwind_Health_Plus_Benefits_Details (1).pdf\n",
            "Northwind_Standard_Benefits_Details.pdf\n",
            "OPEN AI-BASED FILE RETRIEVAL SYSTEM (1).pptx\n",
            "PerksPlus.pdf\n",
            "Wiki.md\n",
            "role_library.pdf\n",
            "test1.pdf\n",
            "test2.pdf\n",
            "test3.pdf\n",
            "test4.pdf\n",
            "test5.pdf\n"
          ]
        }
      ],
      "source": [
        "# Get the container client and blob client\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "blob_client = container_client.get_blob_client(file_name)\n",
        "\n",
        "# List the blobs within the container\n",
        "blob_list = [blob.name for blob in container_client.list_blobs()]\n",
        "print('\\n'.join(blob_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r51DvlL3R8lP"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "from azure.storage.blob import generate_blob_sas, BlobSasPermissions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrpEuFv9TIV-"
      },
      "outputs": [],
      "source": [
        "# Generate the SAS token for the blob\n",
        "# Grant limited access to Azure Storage resources using shared access signatures (SAS)\n",
        "expiry = datetime.utcnow() + timedelta(hours=1)\n",
        "sas_token = generate_blob_sas(\n",
        "    account_name=blob_service_client.account_name,\n",
        "    container_name=container_name,\n",
        "    blob_name=file_name,\n",
        "    account_key=blob_service_client.credential.account_key,\n",
        "    permission=BlobSasPermissions(read=True),\n",
        "    expiry=expiry,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhW3b-ztTgwo",
        "outputId": "715b3d4a-6a58-42d4-b777-6fab21effc7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://ishitagptblob1.blob.core.windows.net/ishita-container-langchain/test1.pdf?se=2023-06-28T18%3A00%3A08Z&sp=r&sv=2022-11-02&sr=b&sig=o1eT1eXmwshStOetYULt5koK6R35jXGjhfZgwVYudQE%3D\n"
          ]
        }
      ],
      "source": [
        "# Create the downloadable link by combining the blob URL and the SAS token\n",
        "blob_url = blob_client.url\n",
        "download_link = f\"{blob_url}?{sas_token}\"\n",
        "\n",
        "# Print the download link\n",
        "print(download_link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noGCyd3iUWcX",
        "outputId": "ef047e27-575a-4d44-a853-ce6ebd0e6e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (0.18.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz, process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rXePWanUO2U",
        "outputId": "e220e8ec-eb10-4e2a-dbd5-892da00cde37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The blob 'test1.pdf' exists.\n"
          ]
        }
      ],
      "source": [
        "#check if blob exists or does not exist\n",
        "if file_name in blob_list:\n",
        "    print(f\"The blob '{file_name}' exists.\")\n",
        "    blob_url = blob_client.url\n",
        "    download_link = f\"{blob_url}?{sas_token}\"\n",
        "else:\n",
        "    closest_match, similarity = process.extractOne(file_name, blob_list)\n",
        "    print(f\"The blob '{file_name}' does not exist. Did you mean '{closest_match}'? (Similarity: {similarity})\")\n",
        "    matches = process.extract(file_name, blob_list, scorer=fuzz.ratio, limit=1)\n",
        "\n",
        "    suggested_blob_name = matches[0][0]\n",
        "    suggested_blob_client = blob_service_client.get_blob_client(container=container_name, blob=suggested_blob_name)\n",
        "    sas_token = suggested_blob_client.generate_shared_access_signature(permission=\"r\")\n",
        "    download_link = f\"{suggested_blob_client.url}?{sas_token}\"\n",
        "    print(f\"Suggested blob name: {suggested_blob_name}\")\n",
        "    print(f\"Downloadable link for the suggested blob: {download_link}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
